Develop PySpark routines to load data from Spark DataFrames and save it into Hive tables in an optimized format on a Hadoop cluster, de-normalizing the data if required.
•	Write PySpark applications to cleanse the data, prepare the data to handle missing values, and the data transformations identified in task 1.1, making sure that the data is written into Hive tables in an efficient format as well.
•	Ensure that the best practices are followed, and the design & code use the features of Spark and take advantage of them.
